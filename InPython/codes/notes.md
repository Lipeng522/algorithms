# 1. 算法引入

以下为数据结构与算法基础学习笔记部分，由张超于2019年4月27日完成。

笔记一部分采撷自学习资料，一部分为自己的学习心得，代码实现部分单独列出。

## 1.1 引例
如果 a+b+c=1000，且 a^2+b^2=c^2（a,b,c 为自然数），如何求出所有a、b、c可能的组合?
## 1.2 算法的5个特性：
1. 输入
2. 输出
3. 有穷性
4. 确定性
5. 可行性
## 1.4 算法效率衡量
### 时间复杂度与“大O记法”
n ^3，是一个**数量级**的概念。

“大O记法”：对于单调的整数函数f，如果存在一个整数函数g和实常数c>0，使得对于充分大的n总有f(n)<=c*g(n)，就说函数g是f的一个渐近函数（忽略常数），记为f(n)=O(g(n))。也就是说，在趋向无穷的极限意义下，函数f的增长速度受到函数g的约束，亦即函数f与函数g的特征相似。

时间复杂度：假设存在函数g，使得算法A处理规模为n的问题示例所用时间为T(n)=O(g(n))，则称O(g(n))为算法A的渐近时间复杂度，简称时间复杂度，记为T(n)

对于算法进行特别具体的细致分析虽然很好，但在实践中的实际价值有限。对于算法的时间性质和空间性质，最重要的是其数量级和趋势，这些是分析算法效率的主要部分。而计量算法基本操作数量的规模函数中那些常量因子可以忽略不计。例如，可以认为3n2和100n2属于同一个量级，如果两个算法处理同样规模实例的代价分别为这两个函数，就认为它们的效率“差不多”，都为n2级。
### 最坏时间复杂度
同样的算法，处理不同数据时间和步骤可能不同，算法完成工作最多需要多少基本操作，即最坏时间复杂度。

我们主要关注算法的最坏情况，亦即最坏时间复杂度。
### 时间复杂度的几条基本计算规则
顺序：时间复杂度按**加法**进行计算
条件：时间复杂度取**最大值**
循环：时间复杂度按**乘法**进行计算

例：T(n) = n * n * ( 1 + max(1, 0) ) = n^2 *2 = O(n^2)
### 常见时间复杂度之间关系
O(1) < O(logn) < O(n) < O(nlogn) < O(n^2) < O(n^3) < O(2^n) < O(n!) < O(n^n)
## 1.7 Python内置类型性能分析
见O02_list.py
### list内置操作的时间复杂度
### dict内置操作的时间复杂度
## 1.8 数据结构
> 用Python中的类型来保存一个班的学生信息

一组数据的组织方式，解决数据如何保存的问题。
Python中的字典、列表、元组已经是封装的高级的数据结构了，数据结构是对基本数据类的一种封装。
### 算法与数据结构区别
数据结构只是静态的描述了数据元素之间的关系。

高效的程序需要在数据结构的基础上设计和选择算法。

**程序 = 数据结构 + 算法

总结：算法是为了解决实际问题而设计的，数据结构是算法需要处理的问题载体**
### 抽象数据类型 ADT
抽象数据类型(ADT)的含义是指一个数学模型以及定义在此数学模型上的一组操作。即把数据类型和数据类型上的运算捆在一起，进行封装。引入抽象数据类型的目的是把数据类型的表示和数据类型上运算的实现与这些数据类型和运算在程序中的引用隔开，使它们相互独立。

最常用的数据运算有五种：插入，删除，修改，查找，排序

# 2. 顺序表
## 内存
存放数据，直接与CPU交换数据。内存以一个字节（8位）作为索引单位。

地址：0X01, 空间：一个8位存储单元。以此类推
### int数据
一个int数据，要占多少存储单元？对于32位，要占4个字节，每个字节8位。
int a = 1，二进制 = 0000 0001：

0X01：0000 0000

0X02：0000 0000 

0X03：0000 0000

0X04：0000 0001 
### char数据
一个char数据，对于32位，要占1个字节，每个字节8位。

### 存储
int = 1, 2, 3

地址：0X01, 0X05, 0X09

定位第三个数据可以从第一个数据的地址计算得到。故连续存储时，进行索引很方便。
## 2.1 顺序表的形式
### 顺序表基本布局
一组相同类型的元素。
li = [200, 390, 78, 12112]

200, (4Byte = 32) 390, 78, 12112

一次向操作系统申请16个字节，若200地址为0X23，0X27, 0X31, 0X35。

li这个变量名就是0X23。

li[0]从0X23开始读4个字节。li[3]代表第4个元素：

li[3] = 0X23 + 3*4Byte

访问指定元素无需从头遍历，通过计算便可获得对应地址，时间复杂度为O(1)
### 元素外置的顺序表
如果元素的大小（每个数据占用的空间）不统一，存储单元相应的编号是地址，（32位）地址是4个字节。

0X324: 0X100 -> 12

0X328: 0X200 -> "ab"

0X332: 0X53 -> 1.111

0X336: 0X110 -> 1000

地址占用空间大小相同，则列表中每一个数据都是地址，地址再指向真正的数据。
现在把四个地址存起来，每个地址是4个字节，要申请16个字节
此时li指向0X324。
## 2.2 顺序表的结构与实现
### 顺序表的结构
表头信息：为实现正确操作而需记录的信息

容量：8；

当前元素个数：4

数据区：表中元素的集合

li[8]
### 顺序表的两种基本实现方式
一体式结构：表头直接加数据

分离式结构：表头+数据的地址

### 元素存储区替换
一体式结构：数据扩展时，要重新向操作系统申请5（数据）+2（表头）个大小空间，每个空间为空，接着数据搬迁。
原先li对应的地址就变了。

分离式：数据扩展时，表头就不用变了。li对应的表头的起始地址不变。

通常都会使用**分离式**。

### 元素存储区扩充
因为有扩充，所以要替换。

动态顺序表：容量可以在使用中动态变化。

#### 扩充的两种策略
扩充固定数目的存储位置：以时间换空间

每次扩充增加一倍存储空间：以空间换时间
## 2.3 顺序表的操作
### 增加元素
a. 尾端加入元素，时间复杂度为O(1)

b. 非保序的加入元素（不常见），时间复杂度为O(1)

c. 保序的元素加入，时间复杂度为O(n)

### 删除元素
a. 删除表尾元素，时间复杂度为O(1)

b. 非保序的元素删除（不常见），时间复杂度为O(1)

c. 保序的元素删除，时间复杂度为O(n)
## 2.4 Python中的顺序表
list：可变类型的顺序表

tuple：不可变类型，不支持内部状态的任何操作，其他方面与list性质类似。

### list的基本实现技术
见课本

# 3. 链表
## 链表简介
（连续存储的）**顺序表**和（线串起来的）**链表**统称为**线性表**

链表（Linked list）是一种常见的基础数据结构，是一种线性表，但是不像顺序表一样连续存储数据，而是在每一个**节点**（数据存储单元）里存放下一个节点的位置信息（即地址）。

li = [200, 300 ,400]

0X11[200|300的地址:0X34] -> 0X34[300|400的地址:OX21] -> 0X21[400|空值]

即[数据区|链接区] 即 数据 + 下一个节点的位置
## 3.1 单向链表
单向链表也叫单链表，是链表中最简单的一种形式，它的每个节点包含两个域，一个信息域（元素域）和一个链接域。这个链接指向链表中的下一个节点，而最后一个节点的链接域则指向一个空值。

头结点：第一个节点

尾节点：最后一个节点
### 什么是节点的实现
首先，数据结构用程序去写，是一个类。

产生一个数据结构时，要把关于这个数据结构以及他所支持的操作放到一起，形成一个整体，即面向对象当中的类。

一方面：解决数据的保存问题

一方面：定义出对于这样的数据结构到底支持哪一种操作。
### 节点和链表的实现

#### 前提
##### 以交换为例
a = 10

b = 20

a, b = b, a （a,b交换）

a, b = 20, 10 （从右到左考虑）

a, b保存对象的地址

##### Python是隐式声明
别的语言构造一个对象要声明类型；

python隐式声明：a = 10 时，a真正代表的是一个内存，内存中保存的是一块地址，地址指向什么，那么a这个变量就指向什么。

a = 10，a中并没有保存10，10不是a中的一部分，而是10的地址。

##### 以类为例
一个类保存为一个对象，这个对象保存的是什么。

链表中，每个节点：数据区+链接区。将其封装为一个类，这个类中包含两个数据：elem + next。

比如:

Node1: elem=10, next=node2

Node2: elem=20, next

不是把node2放进来，而是next这个标签，指向node2所在的区域；这个"="就是引用的连接。

#### 节点和链表的实现

##### 创建
sll = SingleLinkList()

sll: _head -> None

node = Node(100)

sll: _head -> node[100|None]

##### 示例
sll: _head -> node1[100|node2] -> node2[200|node3] -> node3[300|None] -> None

实例节点：

pre 前节点

cur 当前节点

后继结点
### 链表与顺序表的对比
见书

比如插入/删除：链表O(n)是花费在遍历上；顺序表O(n)是花费在数据搬迁上。代表的操作不一样。
## 3.3 双向链表
### 双向链表及添加元素
后继结点：当前节点的下一个

前驱节点：当前节点的前一个

__head = [p|100|n] <=> [p|200|n] <=> [p|200|n]
node[p|item|n]
## 3.2 单向循环列表

# 数据结构注意事项
## 缓冲区node
def f(self, item)

有无输入元素，需不需要创建node = Node(item)
## 游标
### cur
当前位置的游标，最常用

初始化：cur = self.__head
### pre
当前位置的前一位置的游标，在单链表里用。双链表每一节点有prev

初始化：pre = None
### 游标后移
cur = cur.next
pre = pre.next
## 计数
length，insert这种涉及个数或位置的

初始化：

count = 0

count = 1：需考虑 空链表 count = 0 的特殊情况
## 遍历循环
### while cur.next is not None（或某元素）
此时当前位置cur仍满足条件，但已不进入循环
### while cur is not None （或某元素）
此时当前位置cur已不满足条件，最后一个满足条件的cur.prev之前已进入循环
## 节点指向变化
通过画图、指向来一步步完成。

A -> B，A指向B，即将B的地址赋给A，结构为：A = B
## 检查
### 链表层面
#### 链表为空
#### 链表仅有一个节点

### 结点元素层面
#### 所判断元素为第一个节点
#### 所判断元素为最后一个结点

# 4. 栈
栈的实现

# 5. 队列
## 队列的实现
07_queue
## 双端队列
08_deque

# 6. 排序算法
稳定性：稳定排序算法会让原本有相等键值的纪录维持相对次序。
## 6.1 冒泡排序
最优时间复杂度：O(n) （表示遍历一次发现没有任何可以交换的元素，排序结束。）

最坏时间复杂度：O(n2)

稳定性：稳定

## 6.2 选择排序
最优时间复杂度：O(n2)

最坏时间复杂度：O(n2)

稳定性：不稳定（考虑升序每次选择最大的情况）

## 6.3 插入排序
最优时间复杂度：O(n) （升序排列，序列已经处于升序状态）
最坏时间复杂度：O(n2)
稳定性：稳定

## 6.4 快速排序
最优时间复杂度：O(nlogn)
最坏时间复杂度：O(n2)
稳定性：不稳定

## 6.5 希尔排序
### 希尔排序
希尔排序(Shell Sort)是插入排序的一种。也称缩小增量排序，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。该方法因DL．Shell于1959年提出而得名。 希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。

### 希尔排序过程
希尔排序的基本思想是：将数组列在一个表中并对列分别进行插入排序，重复这过程，不过每次用更长的列（步长更长了，列数更少了）来进行。最后整个表就只有一列了。将数组转换至表是为了更好地理解这算法，算法本身还是使用数组进行排序。

### 时间复杂度
最优时间复杂度：根据步长序列的不同而不同
最坏时间复杂度：O(n2)
稳定想：不稳定

### 希尔排序为什么那么快
原始的那种增量，即从length逐步减半，其实这还不算最快的希尔，有几个增量在实践中表现更出色，具体可以看weiss的数据结构书，同时里面有希尔排序复杂度的证明，但是涉及组合数学和数论。

希尔排序是实现简单但是分析极其困难的一个算法的例子至于楼主问为啥希尔能突破O(N^2)的界，可以用逆序数来理解。

假设我们要从小到大排序，一个数组中取两个元素如果前面比后面大，则为一个逆序，容易看出排序的本质就是消除逆序数，可以证明对于随机数组，逆序数是O(N^2)的，而如果采用“交换相邻元素”的办法来消除逆序，每次正好只消除一个，因此必须执行O(N^2)的交换次数，这就是为啥冒泡、插入等算法只能到平方级别的原因，反过来，基于交换元素的排序要想突破这个下界，必须执行一些比较，交换相隔比较远的元素，使得一次交换能消除一个以上的逆序，希尔、快排、堆排等等算法都是交换比较远的元素，只不过规则各不同罢了

### 举例阐释
假设从小到大排序，简单起见设数组元素两两不等

现在发现了a[i]>a[j]，i<j，考虑下标闭区间[i,j]这个范围的j-i+1个元素，对任意i<k<j，考虑a[k]

若a[k]<a[j]，交换a[i]和a[j]后，三者的逆序数从2变为1（例如3 1 2变成2 1 3）

若a[k]>a[i]，交换a[j]和a[i]后，三者的逆序数从2变为1（例如2 3 1变成1 3 2）

若a[i]>a[k]>a[j]，交换a[i]和a[j]后，三者的逆序数从3变为0（例如3 2 1变成1 2 3）

当然，上面每条都重复计算了a[i]和a[j]的逆序关系，但是减掉重复计算的数量，每次交换，逆序数也必然是递减的，除非你去交换两个本来就有序的元素

## 6.7. 归并算法
### 归并排序
归并排序是采用分治法的一个非常典型的应用。归并排序的思想就是先递归分解数组，再合并数组。

将数组分解最小之后，然后合并两个有序数组，基本思路是比较两个数组的最前面的数，谁小就先取谁，取了后相应的指针就往后移一位。然后再比较，直至一个数组为空，最后把另一个数组的剩余部分复制过来即可。

### 时间复杂度
最优时间复杂度：O(nlogn)
最坏时间复杂度：O(nlogn)
稳定性：稳定

## 6.8 二分查找
最优时间复杂度：O(1)
最坏时间复杂度：O(logn)

# 7. 叉树
## 7.1 树

### 树的概念

树（英语：tree）是一种抽象数据类型（ADT）或是实作这种抽象数据类型的数据结构，用来模拟具有树状结构性质的数据集合。它是由n（n>=1）个有限节点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。它具有以下的特点：

- 每个节点有零个或多个子节点；
- 没有父节点的节点称为根节点；
- 每一个非根节点有且只有一个父节点；
- 除了根节点外，每个子节点可以分为多个不相交的子树；

### 树的术语

- **节点的度**：一个节点含有的子树的个数称为该节点的度；
- **树的度**：一棵树中，最大的节点的度称为树的度；
- **叶节点**或**终端节点**：度为零的节点；
- **父亲节点**或**父节点**：若一个节点含有子节点，则这个节点称为其子节点的父节点；
- **孩子节点或子节点**：一个节点含有的子树的根节点称为该节点的子节点；
- **兄弟节点**：具有相同父节点的节点互称为兄弟节点；
- 节点的**层次**：从根开始定义起，根为第1层，根的子节点为第2层，以此类推；
- 树的**高度**或**深度**：树中节点的最大层次；
- **堂兄弟节点**：父节点在同一层的节点互为堂兄弟；
- **节点的祖先**：从根到该节点所经分支上的所有节点；
- **子孙**：以某节点为根的子树中任一节点都称为该节点的子孙。
- **森林**：由m（m>=0）棵互不相交的树的集合称为森林；

### 树的种类

- **无序树**：树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树；

- **有序树**：树中任意节点的子节点之间有顺序关系，这种树称为有序树；

  - 二叉树

    ：每个节点最多含有两个子树的树称为二叉树；

    - **完全二叉树**：对于一颗二叉树，假设其深度为d(d>1)。除了第d层外，其它各层的节点数目均已达最大值，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树，其中**满二叉树**的定义是所有叶节点都在最底层的完全二叉树;
    - **平衡二叉树**（AVL树）：当且仅当任何节点的两棵子树的高度差不大于1的二叉树；
    - **排序二叉树**（二叉查找树（英语：Binary Search Tree），也称二叉搜索树、有序二叉树）；

  - **霍夫曼树**（用于信息编码）：带权路径最短的二叉树称为哈夫曼树或最优二叉树；

  - **B树**：一种对读写操作进行优化的自平衡的二叉查找树，能够保持数据有序，拥有多余两个子树

## 7.2 二叉树

### 二叉树的基本概念

二叉树是每个节点最多有两个子树的树结构。通常子树被称作“左子树”（left subtree）和“右子树”（right subtree）

### 二叉树的性质

**性质1:** 在二叉树的第i层上至多有2^(i-1)个结点（i>0）
**性质2:** 深度为k的二叉树至多有2^k - 1个结点（k>0）
**性质3:** 对于任意一棵二叉树，如果其叶结点数为N0，而度数为2的结点总数为N2，则N0=N2+1;
**性质4:**具有n个结点的完全二叉树的深度必为 log2(n+1)
**性质5:**对完全二叉树，若从上至下、从左至右编号，则编号为i 的结点，其左孩子编号必为2i，其右孩子编号必为2i＋1；其双亲的编号必为i/2（i＝1 时为根,除外）

### 二叉树的遍历

#### 层次遍历

一层一层，从根往叶，进行遍历。

#### 先序遍历

根，左，右

#### 中序遍历

左，根，右

#### 后序遍历

左，右，根

#### 问题：给出某两种，写出树
例：
先：0 1 3 7 8 4 9 2 5 6
中：7 3 8 1 9 4 0 5 2 6
         0
     1         2
  3     4   5   6
7   8  9